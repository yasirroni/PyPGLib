{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matpower import start_instance\n",
    "from matpowercaseframes import CaseFrames\n",
    "from oct2py.core import Oct2PyError\n",
    "\n",
    "from pypglib import PATH_PYPGLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../bench\"\n",
    "output_dir_opf = os.path.join(output_dir, \"opf\")\n",
    "\n",
    "os.makedirs(output_dir_opf, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = start_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_sol_to_json(sol, output_dir, file_name):\n",
    "    def convert_ndarray(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "    json_file_path = os.path.join(output_dir, f\"{file_name}.json\")\n",
    "\n",
    "    with open(json_file_path, \"w\") as json_file:\n",
    "        json.dump(sol, json_file, indent=4, default=convert_ndarray)\n",
    "\n",
    "\n",
    "def extract_sol(mpc, m):\n",
    "    # NOTE: too big if pull rundcopf data\n",
    "    #   m.eval(\"_r1.raw = rmfield(_r1.raw, 'task');\")\n",
    "    #   m.eval(\"_r1 = rmfield(_r1, 'om');\")\n",
    "    #   sol = m.pull(\"_r1\")\n",
    "\n",
    "    sol = {\n",
    "        \"baseMVA\": mpc.baseMVA,\n",
    "        \"version\": mpc.version,\n",
    "        \"bus\": m.eval(\"_r1.bus;\", verbose=False),\n",
    "        \"gen\": m.eval(\"_r1.gen;\", verbose=False),\n",
    "        \"branch\": m.eval(\"_r1.branch;\", verbose=False),\n",
    "        \"gencost\": mpc.gencost,\n",
    "        \"success\": m.eval(\"_r1.success;\", verbose=False),\n",
    "    }\n",
    "    return sol\n",
    "\n",
    "\n",
    "def run_ed(sol, mpopt):\n",
    "    # TODO: check at least voltages and power constraints\n",
    "    if sol[\"success\"] == 1:\n",
    "        sol_ed = m.runpf(sol, mpopt, verbose=False)\n",
    "        if sol_ed[\"success\"] == 1:\n",
    "            status = \"Success\"\n",
    "            cost = m.totcost(sol_ed[\"gencost\"], sol_ed[\"gen\"][:, [PG]]).sum()\n",
    "        else:\n",
    "            status = \"Not Converge\"\n",
    "            cost = \"--\"\n",
    "    else:\n",
    "        sol_ed = {}\n",
    "        status = \"Infeasible\"\n",
    "        cost = \"inf\"  # Infeasible solution\n",
    "    return sol_ed, status, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG = 1  # index for PG\n",
    "opf_dir = os.path.join(PATH_PYPGLIB, \"opf\")\n",
    "mpopt = m.mpoption(\"verbose\", 0, \"out.all\", 0)\n",
    "m.push(\"_mpopt\", mpopt)\n",
    "\n",
    "csv_file_path = os.path.join(output_dir_opf, \"opf_benchmark_results.csv\")\n",
    "fieldnames = [\n",
    "    \"file_name\",\n",
    "    \"matpower-pip_status\",\n",
    "    \"matpower-pip_cost\",\n",
    "    \"matpower-pip_python_time_perf\",\n",
    "]\n",
    "\n",
    "# create results and check already run case\n",
    "if not os.path.isfile(csv_file_path):\n",
    "    with open(csv_file_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "df_results = pd.read_csv(csv_file_path)\n",
    "file_names_m = df_results[\"file_name\"].tolist()\n",
    "\n",
    "file_paths = list(glob.glob(os.path.join(opf_dir, \"**\", \"*.m\"), recursive=True))\n",
    "for file_path in file_paths:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if file_name in file_names_m:\n",
    "        continue\n",
    "\n",
    "    mpc = m.loadcase(file_path)\n",
    "    try:\n",
    "        start_time_perf = time.perf_counter()\n",
    "        m.push(\"_mpc\", mpc)\n",
    "        m.eval(\"_r1 = runopf(_mpc, _mpopt);\", verbose=False)\n",
    "        sol = extract_sol(mpc, m)\n",
    "        python_time_perf = time.perf_counter() - start_time_perf\n",
    "\n",
    "        sol_ed, status, cost = run_ed(sol, mpopt)\n",
    "    except Oct2PyError as e:\n",
    "        print(e)\n",
    "        print(file_name)\n",
    "        sol = {}\n",
    "        status = \"Error\"\n",
    "        cost = \"Err\"\n",
    "        python_time_perf = np.inf\n",
    "\n",
    "    # NOTE: json is too big, 5 MB for single case\n",
    "    # dump_sol_to_json(sol, output_dir_opf, file_name)  # too big\n",
    "\n",
    "    try:\n",
    "        base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        cf = CaseFrames(sol)\n",
    "        cf.gen.to_csv(os.path.join(output_dir_opf, f\"{base_name}.gen.csv\"))\n",
    "        # cf.bus.to_csv(\n",
    "        #     os.path.join(output_dir_opf, f\"{base_name}.bus.csv\")\n",
    "        # )\n",
    "    except AttributeError:\n",
    "        # errors\n",
    "        pass\n",
    "\n",
    "    with open(csv_file_path, mode=\"a\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writerow(\n",
    "            {\n",
    "                \"file_name\": file_name,\n",
    "                \"matpower-pip_status\": status,\n",
    "                \"matpower-pip_cost\": cost,\n",
    "                \"matpower-pip_python_time_perf\": python_time_perf,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG = 1  # index for PG\n",
    "opf_dir = os.path.join(PATH_PYPGLIB, \"opf\")\n",
    "mpopt = m.mpoption(\"verbose\", 0, \"out.all\", 0)\n",
    "m.push(\"_mpopt\", mpopt)\n",
    "\n",
    "csv_file_path = os.path.join(output_dir_opf, \"dcopf_benchmark_results.csv\")\n",
    "fieldnames = [\n",
    "    \"file_name\",\n",
    "    \"matpower-pip_dcopf_status\",\n",
    "    \"matpower-pip_dcopf_cost\",\n",
    "    \"matpower-pip_dcopf_python_time_perf\",\n",
    "]\n",
    "\n",
    "# create results and check already run case\n",
    "if not os.path.isfile(csv_file_path):\n",
    "    with open(csv_file_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "df_results = pd.read_csv(csv_file_path)\n",
    "file_names_m = df_results[\"file_name\"].tolist()\n",
    "\n",
    "file_paths = list(glob.glob(os.path.join(opf_dir, \"**\", \"*.m\"), recursive=True))\n",
    "for file_path in file_paths:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if file_name in file_names_m:\n",
    "        continue\n",
    "\n",
    "    mpc = m.loadcase(file_path)\n",
    "    try:\n",
    "        start_time_perf = time.perf_counter()\n",
    "        m.push(\"_mpc\", mpc)\n",
    "        m.eval(\"_r1 = rundcopf(_mpc, _mpopt);\", verbose=False)\n",
    "        sol = extract_sol(mpc, m)\n",
    "        python_time_perf = time.perf_counter() - start_time_perf\n",
    "\n",
    "        sol_ed, status, cost = run_ed(sol, mpopt)\n",
    "\n",
    "    except Oct2PyError as e:\n",
    "        print(e)\n",
    "        print(file_name)\n",
    "        sol = {}\n",
    "        status = \"Error\"\n",
    "        cost = \"Err\"\n",
    "        python_time_perf = np.inf\n",
    "\n",
    "    # NOTE: json is too big, 5 MB for single case\n",
    "    # dump_sol_to_json(sol, output_dir_opf, file_name)  # too big\n",
    "\n",
    "    try:\n",
    "        base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "        cf = CaseFrames(sol)\n",
    "        cf.gen.to_csv(os.path.join(output_dir_opf, f\"{base_name}_dcopf.gen.csv\"))\n",
    "        # cf.bus.to_csv(\n",
    "        #     os.path.join(output_dir_opf, f\"{base_name}.bus.csv\")\n",
    "        # )\n",
    "    except AttributeError:\n",
    "        # errors\n",
    "        pass\n",
    "\n",
    "    with open(csv_file_path, mode=\"a\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writerow(\n",
    "            {\n",
    "                \"file_name\": file_name,\n",
    "                \"matpower-pip_dcopf_status\": status,\n",
    "                \"matpower-pip_dcopf_cost\": cost,\n",
    "                \"matpower-pip_dcopf_python_time_perf\": python_time_perf,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   file_name matpower-pip_status  matpower-pip_cost  matpower-pip_python_time_perf\n",
      "0   pglib_opf_case4837_goc.m             Success       8.722553e+05                      23.271484\n",
      "1  pglib_opf_case2746wop_k.m             Success       1.208259e+06                      14.201063\n",
      "2   pglib_opf_case4601_goc.m             Success       8.262416e+05                      18.952148\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_dir_opf, exist_ok=True)\n",
    "df_results = pd.read_csv(csv_file_path)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io\n",
    "# import julia\n",
    "# from julia import Main\n",
    "\n",
    "# # Initialize Julia and load the required packages\n",
    "# julia.Julia(compiled_modules=False)\n",
    "# Main.eval(\n",
    "# \"\"\"\n",
    "# using JuMP, PowerModels, Ipopt\n",
    "# solver = optimizer_with_attributes(Ipopt.Optimizer, \"tol\"=>1e-6)\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "# # List of case files to run (replace with actual .mat file paths or data objects)\n",
    "# case_files = [\"case1.mat\", \"case2.mat\", \"case3.mat\"]\n",
    "\n",
    "# # To store the results\n",
    "# results = []\n",
    "\n",
    "# # Loop through each case and run the optimization\n",
    "# for case_file in case_files:\n",
    "#     # Load the .mat file using scipy.io in Python\n",
    "#     mat_data = scipy.io.loadmat(case_file)\n",
    "\n",
    "#     # Pass the .mat data to Julia\n",
    "#     Main.mat_data = mat_data\n",
    "\n",
    "#     # Run the AC Optimal Power Flow in Julia and capture the result\n",
    "#     result = Main.eval('run_ac_opf(mat_data, solver)')\n",
    "\n",
    "#     # Store the result in the Python results list\n",
    "#     results.append(result)\n",
    "\n",
    "# # Now `results` contains the optimization results for each case\n",
    "# for i, res in enumerate(results):\n",
    "#     print(f\"Result for case {i+1}: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
